{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Acer'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\acer\\anaconda3\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow) (1.20.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow) (3.10.0.2)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow) (12.0.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow) (1.43.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: tensorboard~=2.6 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow) (0.23.1)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow) (3.2.1)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.3.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (58.0.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\acer\\anaconda3\\lib\\site-packages (2.7.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pickle-mixin in c:\\users\\acer\\anaconda3\\lib\\site-packages (1.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pickle-mixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\acer\\anaconda3\\lib\\site-packages (3.6.5)\n",
      "Requirement already satisfied: click in c:\\users\\acer\\anaconda3\\lib\\site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\acer\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from nltk) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\acer\\anaconda3\\lib\\site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\acer\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chatbot = {\n",
    "    \"intents\": [{\n",
    "            \"tag\": \"greetings\",\n",
    "            \"patterns\": [\"hi there\", \"hello\",\"haroo\",\"yaw\",\"wassup\", \"hi\", \"hey\", \"holla\", \"hello\"],\n",
    "            \"responses\": [\"hello thanks for checking in\", \"hi there, how can i help you\"],\n",
    "            \"context\": [\"\"]\n",
    "        },\n",
    "        {\n",
    "            \"tag\": \"goodbye\",\n",
    "            \"patterns\": [\"bye\", \"good bye\", \"see you later\"],\n",
    "            \"responses\": [\"have a nice time, welcome back again\", \"bye bye\"],\n",
    "            \"context\": [\"\"]\n",
    "        },\n",
    "        {\n",
    "            \"tag\": \"thanks\",\n",
    "            \"patterns\": [\"Thanks\", \"okay\",\"Thank you\",\"thankyou\", \"That's helpful\", \"Awesome, thanks\", \"Thanks for helping me\", \"wow\", \"great\"],\n",
    "            \"responses\": [\"Happy to help!\", \"Any time!\",\"you're welcome\", \"My pleasure\"],\n",
    "            \"context\": [\"\"]\n",
    "        },\n",
    "        {\n",
    "            \"tag\": \"noanswer\",\n",
    "            \"patterns\": [\"\"],\n",
    "            \"responses\": [\"Sorry, I didn't understand you\", \"Please give me more info\", \"Not sure I understand that\"],\n",
    "            \"context\": [\"\"]\n",
    "        },\n",
    "        {\n",
    "            \"tag\": \"name1\",\n",
    "            \"patterns\": [\"what's your name?\",\"who are you?\"],\n",
    "            \"responses\": [\"I'm just an SDF agent. I only exist in the world of DoFPD\",\"I'm a SDF chat agent\"],\n",
    "            \"context\": [\"\"]\n",
    "        },\n",
    "        {\n",
    "            \"tag\": \"name\",\n",
    "            \"patterns\": [\"my name is \", \"I'm \",\"I am\"],\n",
    "            \"responses\": [\"Oooh great to meet you ! How may I assist you \", \"Oh, I'll keep that in mind\"],\n",
    "            \"context\": [\"\"]\n",
    "        },\n",
    "        {\n",
    "            \"tag\": \"Rice Fortification\",\n",
    "            \"patterns\": [\"What is Rice Fortification ?\", \"Rice Fortification\",\n",
    "                         \"Please explain what is rice fortification\", \n",
    "                         \"How to define rice fortification ?\", \n",
    "                         \"Rice Fortification\"],\n",
    "            \"responses\": [\"Fortification of Rice is the process of increasing essential micronutrients in rice,so as to improve the nutritional quality of the food.\", \n",
    "                          \"Rice fortification is the process of increasing essential micronutrients in rice, in order to improve the nutritional quality of food.\",\n",
    "                         \"Rice fortification involves increasing the essential micronutrients of rice to improve the nutritional quality of food.\", \n",
    "                         \"Rice fortification consists of increasing the essential micronutrients of rice in order to improve the nutritional quality of food.\", \n",
    "                         \"Rice fortification involves increasing the essential micronutrients of rice to enhance the nutritional quality of food.\"],\n",
    "            \"context\": [\"\"]\n",
    "        },\n",
    "        {\n",
    "            \"tag\": \"Process of Rice Fortification\",\n",
    "            \"patterns\": [\"How Fortification of Rice is done?\", \"What is the process of Rice Fortification\",\n",
    "                         \"Brief the process of rice fortification\"],\n",
    "            \"responses\": [\"Well! It is very simple process adding Fortified Rice Kernels (FRK) containing FSSAI prescribed micronutrients (Iron, Folic Acid, Vitamin B12)to normal Rice(Custom Milled Rice) in the ratio of 1:100. This process is done in the rice mills at the time of milling of rice and before bagging.\",\n",
    "                          \"This process is done in the rice mills at the time of milling of rice and before bagging by adding fortified rice kernels containing FSSAI prescribed micronutrients that is ; Iron, Folic Acid, Vitamin B12 to the normal rice in the ratio of 1:100 \",\n",
    "                          \"Fortification consists of adding enriched rice grains (FRK) containing micronutrients prescribed by the FSSAI (iron, folic acid, vitamin B12) to normal rice (custom milled rice) in a ratio of 1:100.\",\n",
    "                         \"Fortification consists of adding fortified rice grains (FRK) containing micronutrients prescribed by the FSSAI (iron, folic acid, vitamin B12) to normal rice (custom ground rice) in a ratio of 1:100.\"],\n",
    "            \"context\": [\"\"]\n",
    "        },\n",
    "        {\n",
    "            \"tag\": \"Micronutrients\",\n",
    "            \"patterns\": [\"What are the Micronutrients added for Fortification of Rice?\", \n",
    "                         \"Micronutrients added for Fortification of Rice\", \n",
    "                        \"What are the significant Micronutrients added for Fortification of Rice\"],\n",
    "            \"responses\": [\"In accordance with FSSAI standards, rice is fortified with iron, folic acid and vitamin B12.\",\n",
    "                         \"Under FSSAI standards, rice is enriched with iron, folic acid and vitamin B12.\",\n",
    "                         \"According to FSSAI standards, rice is fortified with iron, folate and vitamin B12.\",\n",
    "                         \"According to FSSAI guidelines, rice is fortified with iron, folic acid and vitamin B12.\",\n",
    "                         \"In accordance with the FSSAI, rice is fortified with iron, folic acid and vitamin B12.\",\n",
    "                         \"According to FSSAI regulations, rice is fortified with iron, folic acid and vitamin B12.\",\n",
    "                         \"According to FSSAI standards, rice is rich in iron, folic acid and vitamin B12.\",\n",
    "                         \"In accordance with FSSAI standards, rice is fortified with iron, folate and vitamin B12.\"],\n",
    "            \"context\": [\"\"]\n",
    "        },\n",
    "        {\n",
    "            \"tag\": \"FSSAI Standards\",\n",
    "            \"patterns\": [\"What are the FSSAI standards for Fortified Rice?\",\n",
    "                        \"What are the FSSAI requirements for fortified rice?\",\n",
    "                        \"What are the FSSAI standards for fortification rice?\"],\n",
    "            \"responses\": [\"As per FSSAI, Rice when fortified, shall contain the micronutrients at the level will be : Iron (Ferric Pyrophosphate) = 28mg to 42.5mg per Kg, Sodium Iron (III) Ethylene Diamine tetra Acetate Trihydrate (Sodium Feredetate - Na Fe EDTA) = 14mg to 21.25mg per Kg, Folic Acid = 75µg to 125µg per Kg, Vitamin B12 (Cyanocobalamine or Hydroxycobalamine) = 0.75µg to 1.25µg per Kg\"],\n",
    "            \"context\": [\"\"]\n",
    "        },\n",
    "        {\n",
    "            \"tag\": \"technologies available for Fortification of Rice\",\n",
    "            \"patterns\": [\"What are the various technologies available for Fortification of Rice?\",\n",
    "                        \"technologies available for Fortification of Rice\",\n",
    "                        \"Rice Fortification Technologies\"],\n",
    "            \"responses\": [\"Theyare: coating, extrusion and dusting\",\n",
    "                         \"There are three main technologies available to produce fortified rice. Theyare: coating, extrusion and dusting\",\n",
    "                         \"Three main technologies available to produce fortified rice. Theyare: coating, extrusion and dusting.\",\n",
    "                         \"Technologies used for rice fortification are ; Theyare: coating, extrusion and dusting\"],\n",
    "            \"context\": [\"\"]\n",
    "        },\n",
    "        {\n",
    "            \"tag\": \"Fortification Technology available in India\",\n",
    "            \"patterns\": [\"What is the rice fortification technology available in India?\",\n",
    "                        \"Fortification Technology available in India\",\n",
    "                        \"Technologies which are available in India\"],\n",
    "            \"responses\": [\"In India, rice is fortified using extrusion technology.\",\n",
    "                         \"Extrusion is the technology where In this technology,milled rice is pulverized and mixed with a premix containing vitamins andminerals.Fortified rice kernels (FRK) are produced from this mixture usingan extruder machine. FRK is added to milled rice in ratio of 1:100. Fortified rice nearly identical to traditional rice inaroma, taste, and texture.\"],\n",
    "            \"context\": [\"\"]\n",
    "        },\n",
    "        {\n",
    "            \"tag\": \"Extrusion in India\",\n",
    "            \"patterns\": [\"Why is extrusion the technology is found to be suitable in India?\", \n",
    "                         \"Why extrusion technology is most suitable\"],\n",
    "            \"responses\": [\"Extrusion technology is most suitable becasue it maintain stability of micronutrients\",\n",
    "                         \"Stability of micronutrients can be maintained using extrusion technology, Moreover, in the rice kernelsacross processing, storage, washing and cooking also in view of the costconsiderations\"],\n",
    "            \"context\": [\"\"]\n",
    "        },\n",
    "        {\n",
    "            \"tag\": \"Blending of Rice\",\n",
    "            \"patterns\": [\"How are the fortified rice kernels blended with the normal rice?\", \n",
    "                         \"What are the bledning process?\",\n",
    "                         \"Blending Process\", \n",
    "                         \"I don't know what is blending process please explain what is blending process\"],\n",
    "            \"responses\": [\"There are two types of blending process; one is continous blending and other is batch blending\"],\n",
    "            \"context\": [\"\"]\n",
    "        },\n",
    "        {\n",
    "            \"tag\": \"Difference Between Continous and Batch Blending\",\n",
    "            \"patterns\": [\"What is the difference between Continous and batch blending\",\n",
    "                        \"Batch Bledning and Continous Blending\"],\n",
    "            \"responses\": [\"Continous blending is applicable for large scale blending of the fortified rice\",\n",
    "                         \"where as batch blending is involves the simultaneous addition of fortified ricekernels and the regular rice.Moreover, batch blending assembly usually involves a bin for thefortified rice kernels, through which the kernels are dispensed into theblending unit where the normal rice and kernels are blended\"],\n",
    "            \"context\": [\"\"]\n",
    "        },\n",
    "  \n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_object = json.dumps(Chatbot, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Sample1.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_words = ['?', '!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_file = open(r'C:\\Users\\Acer\\sample1.json').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "intents = json.loads(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intents': [{'tag': 'greetings', 'patterns': ['hi there', 'hello', 'haroo', 'yaw', 'wassup', 'hi', 'hey', 'holla', 'hello'], 'responses': ['hello thanks for checking in', 'hi there, how can i help you'], 'context': ['']}, {'tag': 'goodbye', 'patterns': ['bye', 'good bye', 'see you later'], 'responses': ['have a nice time, welcome back again', 'bye bye'], 'context': ['']}, {'tag': 'thanks', 'patterns': ['Thanks', 'okay', 'Thank you', 'thankyou', \"That's helpful\", 'Awesome, thanks', 'Thanks for helping me', 'wow', 'great'], 'responses': ['Happy to help!', 'Any time!', \"you're welcome\", 'My pleasure'], 'context': ['']}, {'tag': 'noanswer', 'patterns': [''], 'responses': [\"Sorry, I didn't understand you\", 'Please give me more info', 'Not sure I understand that'], 'context': ['']}, {'tag': 'name1', 'patterns': [\"what's your name?\", 'who are you?'], 'responses': [\"I'm just an SDF agent. I only exist in the world of DoFPD\", \"I'm a SDF chat agent\"], 'context': ['']}, {'tag': 'name', 'patterns': ['my name is ', \"I'm \", 'I am'], 'responses': ['Oooh great to meet you ! How may I assist you ', \"Oh, I'll keep that in mind\"], 'context': ['']}, {'tag': 'Rice Fortification', 'patterns': ['What is Rice Fortification ?', 'Rice Fortification', 'Please explain what is rice fortification', 'How to define rice fortification ?', 'Rice Fortification'], 'responses': ['Fortification of Rice is the process of increasing essential micronutrients in rice,so as to improve the nutritional quality of the food.', 'Rice fortification is the process of increasing essential micronutrients in rice, in order to improve the nutritional quality of food.', 'Rice fortification involves increasing the essential micronutrients of rice to improve the nutritional quality of food.', 'Rice fortification consists of increasing the essential micronutrients of rice in order to improve the nutritional quality of food.', 'Rice fortification involves increasing the essential micronutrients of rice to enhance the nutritional quality of food.'], 'context': ['']}, {'tag': 'Process of Rice Fortification', 'patterns': ['How Fortification of Rice is done?', 'What is the process of Rice Fortification', 'Brief the process of rice fortification'], 'responses': ['Well! It is very simple process adding Fortified Rice Kernels (FRK) containing FSSAI prescribed micronutrients (Iron, Folic Acid, Vitamin B12)to normal Rice(Custom Milled Rice) in the ratio of 1:100. This process is done in the rice mills at the time of milling of rice and before bagging.', 'This process is done in the rice mills at the time of milling of rice and before bagging by adding fortified rice kernels containing FSSAI prescribed micronutrients that is ; Iron, Folic Acid, Vitamin B12 to the normal rice in the ratio of 1:100 ', 'Fortification consists of adding enriched rice grains (FRK) containing micronutrients prescribed by the FSSAI (iron, folic acid, vitamin B12) to normal rice (custom milled rice) in a ratio of 1:100.', 'Fortification consists of adding fortified rice grains (FRK) containing micronutrients prescribed by the FSSAI (iron, folic acid, vitamin B12) to normal rice (custom ground rice) in a ratio of 1:100.'], 'context': ['']}, {'tag': 'Micronutrients', 'patterns': ['What are the Micronutrients added for Fortification of Rice?', 'Micronutrients added for Fortification of Rice', 'What are the significant Micronutrients added for Fortification of Rice'], 'responses': ['In accordance with FSSAI standards, rice is fortified with iron, folic acid and vitamin B12.', 'Under FSSAI standards, rice is enriched with iron, folic acid and vitamin B12.', 'According to FSSAI standards, rice is fortified with iron, folate and vitamin B12.', 'According to FSSAI guidelines, rice is fortified with iron, folic acid and vitamin B12.', 'In accordance with the FSSAI, rice is fortified with iron, folic acid and vitamin B12.', 'According to FSSAI regulations, rice is fortified with iron, folic acid and vitamin B12.', 'According to FSSAI standards, rice is rich in iron, folic acid and vitamin B12.', 'In accordance with FSSAI standards, rice is fortified with iron, folate and vitamin B12.'], 'context': ['']}, {'tag': 'FSSAI Standards', 'patterns': ['What are the FSSAI standards for Fortified Rice?', 'What are the FSSAI requirements for fortified rice?', 'What are the FSSAI standards for fortification rice?'], 'responses': ['As per FSSAI, Rice when fortified, shall contain the micronutrients at the level will be : Iron (Ferric Pyrophosphate) = 28mg to 42.5mg per Kg, Sodium Iron (III) Ethylene Diamine tetra Acetate Trihydrate (Sodium Feredetate - Na Fe EDTA) = 14mg to 21.25mg per Kg, Folic Acid = 75µg to 125µg per Kg, Vitamin B12 (Cyanocobalamine or Hydroxycobalamine) = 0.75µg to 1.25µg per Kg'], 'context': ['']}, {'tag': 'technologies available for Fortification of Rice', 'patterns': ['What are the various technologies available for Fortification of Rice?', 'technologies available for Fortification of Rice', 'Rice Fortification Technologies'], 'responses': ['Theyare: coating, extrusion and dusting', 'There are three main technologies available to produce fortified rice. Theyare: coating, extrusion and dusting', 'Three main technologies available to produce fortified rice. Theyare: coating, extrusion and dusting.', 'Technologies used for rice fortification are ; Theyare: coating, extrusion and dusting'], 'context': ['']}, {'tag': 'Fortification Technology available in India', 'patterns': ['What is the rice fortification technology available in India?', 'Fortification Technology available in India', 'Technologies which are available in India'], 'responses': ['In India, rice is fortified using extrusion technology.', 'Extrusion is the technology where In this technology,milled rice is pulverized and mixed with a premix containing vitamins andminerals.Fortified rice kernels (FRK) are produced from this mixture usingan extruder machine. FRK is added to milled rice in ratio of 1:100. Fortified rice nearly identical to traditional rice inaroma, taste, and texture.'], 'context': ['']}, {'tag': 'Extrusion in India', 'patterns': ['Why is extrusion the technology is found to be suitable in India?', 'Why extrusion technology is most suitable'], 'responses': ['Extrusion technology is most suitable becasue it maintain stability of micronutrients', 'Stability of micronutrients can be maintained using extrusion technology, Moreover, in the rice kernelsacross processing, storage, washing and cooking also in view of the costconsiderations'], 'context': ['']}, {'tag': 'Blending of Rice', 'patterns': ['How are the fortified rice kernels blended with the normal rice?', 'What are the bledning process?', 'Blending Process', \"I don't know what is blending process please explain what is blending process\"], 'responses': ['There are two types of blending process; one is continous blending and other is batch blending'], 'context': ['']}, {'tag': 'Difference Between Continous and Batch Blending', 'patterns': ['What is the difference between Continous and batch blending', 'Batch Bledning and Continous Blending'], 'responses': ['Continous blending is applicable for large scale blending of the fortified rice', 'where as batch blending is involves the simultaneous addition of fortified ricekernels and the regular rice.Moreover, batch blending assembly usually involves a bin for thefortified rice kernels, through which the kernels are dispensed into theblending unit where the normal rice and kernels are blended'], 'context': ['']}]}\n"
     ]
    }
   ],
   "source": [
    "print(intents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data \n",
    "for intent in intents['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        #tokenize each word\n",
    "        w = nltk.word_tokenize(pattern)\n",
    "        words.extend(w)\n",
    "        #add documents in the corpus\n",
    "        documents.append((w, intent['tag']))\n",
    "        # add to our classes list\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]\n",
    "words = sorted(list(set(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = sorted(list(set(classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 documents\n"
     ]
    }
   ],
   "source": [
    "print (len(documents), \"documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 classes ['Blending of Rice', 'Difference Between Continous and Batch Blending', 'Extrusion in India', 'FSSAI Standards', 'Fortification Technology available in India', 'Micronutrients', 'Process of Rice Fortification', 'Rice Fortification', 'goodbye', 'greetings', 'name', 'name1', 'noanswer', 'technologies available for Fortification of Rice', 'thanks']\n"
     ]
    }
   ],
   "source": [
    "print (len(classes), \"classes\", classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 unique lemmatized words [\"'m\", \"'s\", ',', 'added', 'am', 'and', 'are', 'available', 'awesome', 'batch', 'be', 'between', 'bledning', 'blended', 'blending', 'brief', 'bye', 'continous', 'define', 'difference', 'do', 'done', 'explain', 'extrusion', 'for', 'fortification', 'fortified', 'found', 'fssai', 'good', 'great', 'haroo', 'hello', 'helpful', 'helping', 'hey', 'hi', 'holla', 'how', 'i', 'in', 'india', 'is', 'kernel', 'know', 'later', 'me', 'micronutrient', 'most', 'my', \"n't\", 'name', 'normal', 'of', 'okay', 'please', 'process', 'requirement', 'rice', 'see', 'significant', 'standard', 'suitable', 'technology', 'thank', 'thanks', 'thankyou', 'that', 'the', 'there', 'to', 'various', 'wassup', 'what', 'which', 'who', 'why', 'with', 'wow', 'yaw', 'you', 'your']\n"
     ]
    }
   ],
   "source": [
    "print (len(words), \"unique lemmatized words\", words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(words,open('words.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(classes,open('classes.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_empty = [0] * len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in documents:\n",
    "    # initialize our bag of words\n",
    "    bag = []\n",
    "    # list of tokenized words for the pattern\n",
    "    pattern_words = doc[0]\n",
    "    # lemmatize each word - create base word, in attempt to represent related words\n",
    "    pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words]\n",
    "    # create our bag of words array with 1, if word match found in current pattern\n",
    "    for w in words:\n",
    "        bag.append(1) if w in pattern_words else bag.append(0)\n",
    "    # output is a '0' for each tag and '1' for current tag (for each pattern)\n",
    "    output_row = list(output_empty)\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "    training.append([bag, output_row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\AppData\\Local\\Temp/ipykernel_7636/2195589081.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  training = np.array(training)\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(training)\n",
    "training = np.array(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = list(training[:,0])\n",
    "train_y = list(training[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data created\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(train_y[0]), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2.7321 - accuracy: 0.0727\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 2.6287 - accuracy: 0.1091\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.5757 - accuracy: 0.2182\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 2.4495 - accuracy: 0.2727\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.2534 - accuracy: 0.4182\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 2.1638 - accuracy: 0.3455\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 798us/step - loss: 2.1536 - accuracy: 0.4000\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 1.8838 - accuracy: 0.4364\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 1.8025 - accuracy: 0.4909\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 630us/step - loss: 1.6588 - accuracy: 0.5455\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 1.6537 - accuracy: 0.5455\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 1.4439 - accuracy: 0.6000\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 1.4000 - accuracy: 0.5273\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 1.3068 - accuracy: 0.6182\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 1.3269 - accuracy: 0.6000\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 1.0977 - accuracy: 0.5818\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 1.1164 - accuracy: 0.7455\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.8456 - accuracy: 0.7818\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.9798 - accuracy: 0.6545\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.7609 - accuracy: 0.8364\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 639us/step - loss: 0.8472 - accuracy: 0.8364\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.8725 - accuracy: 0.7273\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.8307 - accuracy: 0.7273\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 798us/step - loss: 0.7632 - accuracy: 0.8364\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.6098 - accuracy: 0.9273\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.6767 - accuracy: 0.8364\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.5755 - accuracy: 0.8364\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.4990 - accuracy: 0.8909\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.4387 - accuracy: 0.9091\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.4245 - accuracy: 0.9091\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.4063 - accuracy: 0.8545\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.5393 - accuracy: 0.8364\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 798us/step - loss: 0.4848 - accuracy: 0.8727\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.3432 - accuracy: 0.9273\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.4058 - accuracy: 0.8545\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 898us/step - loss: 0.3138 - accuracy: 0.9455\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 997us/step - loss: 0.3140 - accuracy: 0.9273\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 823us/step - loss: 0.4095 - accuracy: 0.8909\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.2861 - accuracy: 0.9091\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.3849 - accuracy: 0.9091\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.3008 - accuracy: 0.8909\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.2705 - accuracy: 0.9273\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.4073 - accuracy: 0.8727\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.3013 - accuracy: 0.9273\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.2495 - accuracy: 0.9818\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.3654 - accuracy: 0.8000\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.3233 - accuracy: 0.9273\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 798us/step - loss: 0.2460 - accuracy: 0.9455\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 726us/step - loss: 0.3652 - accuracy: 0.9091\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.2355 - accuracy: 0.9636\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.3822 - accuracy: 0.8545\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.2191 - accuracy: 0.9636\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.1847 - accuracy: 0.9455\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 798us/step - loss: 0.2859 - accuracy: 0.8909\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.3551 - accuracy: 0.8545\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.2510 - accuracy: 0.9273\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 798us/step - loss: 0.1718 - accuracy: 0.9455\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.1397 - accuracy: 0.9636\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 898us/step - loss: 0.2627 - accuracy: 0.9273\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.1510 - accuracy: 0.9636\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 798us/step - loss: 0.1761 - accuracy: 0.9636\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 897us/step - loss: 0.1380 - accuracy: 0.9636\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.1680 - accuracy: 0.9636\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 798us/step - loss: 0.2447 - accuracy: 0.9455\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.1289 - accuracy: 0.9455\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 798us/step - loss: 0.1365 - accuracy: 0.9818\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 798us/step - loss: 0.1032 - accuracy: 0.9818\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.1986 - accuracy: 0.9455\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 898us/step - loss: 0.1977 - accuracy: 0.9455\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.1668 - accuracy: 0.9636\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.2078 - accuracy: 0.9455\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.1373 - accuracy: 0.9455\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.1224 - accuracy: 0.9818\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 898us/step - loss: 0.1110 - accuracy: 0.9636\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.1480 - accuracy: 0.9818\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 997us/step - loss: 0.2276 - accuracy: 0.9273\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 798us/step - loss: 0.0980 - accuracy: 0.9636\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.1430 - accuracy: 0.9455\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 798us/step - loss: 0.1738 - accuracy: 0.9455\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.1554 - accuracy: 0.9636\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 797us/step - loss: 0.1310 - accuracy: 0.9636\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.1170 - accuracy: 0.9636\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.1085 - accuracy: 0.9636\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 798us/step - loss: 0.0934 - accuracy: 0.9818\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.1455 - accuracy: 0.9636\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 798us/step - loss: 0.0946 - accuracy: 0.9818\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 599us/step - loss: 0.1064 - accuracy: 0.9636\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 798us/step - loss: 0.1593 - accuracy: 0.9636\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 798us/step - loss: 0.1635 - accuracy: 0.9455\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.1331 - accuracy: 0.9636\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 898us/step - loss: 0.1273 - accuracy: 0.9636\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.0956 - accuracy: 0.9818\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.1621 - accuracy: 0.9455\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 798us/step - loss: 0.1094 - accuracy: 0.9636\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.1132 - accuracy: 0.9818\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 898us/step - loss: 0.1160 - accuracy: 0.9455\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.1449 - accuracy: 0.9818\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.1215 - accuracy: 0.9636\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 798us/step - loss: 0.1086 - accuracy: 0.9636\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.1513 - accuracy: 0.9636\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 798us/step - loss: 0.0668 - accuracy: 0.9818\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0492 - accuracy: 0.9818\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.1168 - accuracy: 0.9818\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.1004 - accuracy: 0.9818\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.1921 - accuracy: 0.9273\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.1229 - accuracy: 0.9636\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.1193 - accuracy: 0.9636\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.1409 - accuracy: 0.9455\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 798us/step - loss: 0.0881 - accuracy: 0.9818\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.0574 - accuracy: 0.9818\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.0719 - accuracy: 0.9636\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0869 - accuracy: 0.9636\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0925 - accuracy: 0.9636\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0593 - accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 599us/step - loss: 0.1209 - accuracy: 0.9818\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0677 - accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.1094 - accuracy: 0.9818\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.0942 - accuracy: 0.9636\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.1309 - accuracy: 0.9455\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.0693 - accuracy: 0.9636\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.1388 - accuracy: 0.9636\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.0578 - accuracy: 0.9818\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.1235 - accuracy: 0.9455\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.0937 - accuracy: 0.9818\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 499us/step - loss: 0.1386 - accuracy: 0.9636\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.0906 - accuracy: 0.9455\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0494 - accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0797 - accuracy: 0.9818\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.1564 - accuracy: 0.9455\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0495 - accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0477 - accuracy: 0.9818\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.1448 - accuracy: 0.9636\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0472 - accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0578 - accuracy: 0.9818\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.1080 - accuracy: 0.9455\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0613 - accuracy: 0.9818\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0585 - accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0692 - accuracy: 0.9818\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0429 - accuracy: 0.9818\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0743 - accuracy: 0.9818\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.0296 - accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0583 - accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.1249 - accuracy: 0.9818\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0351 - accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0629 - accuracy: 0.9818\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0548 - accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.1145 - accuracy: 0.9273\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0478 - accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0959 - accuracy: 0.9818\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.1242 - accuracy: 0.9455\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0339 - accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 599us/step - loss: 0.0625 - accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0739 - accuracy: 0.9818\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0922 - accuracy: 0.9818\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0129 - accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.0837 - accuracy: 0.9818\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 499us/step - loss: 0.1471 - accuracy: 0.9455\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0545 - accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.1005 - accuracy: 0.9818\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 599us/step - loss: 0.0831 - accuracy: 0.9818\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.1380 - accuracy: 0.9636\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.0710 - accuracy: 0.9636\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0868 - accuracy: 0.9818\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.0373 - accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0372 - accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0993 - accuracy: 0.9636\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0177 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0463 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0443 - accuracy: 0.9818\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0561 - accuracy: 0.9818\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0261 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 499us/step - loss: 0.0648 - accuracy: 0.9818\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.0591 - accuracy: 0.9818\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 499us/step - loss: 0.0464 - accuracy: 0.9818\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0745 - accuracy: 0.9818\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0353 - accuracy: 0.9818\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.0553 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0560 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0432 - accuracy: 0.9818\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 499us/step - loss: 0.0342 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0399 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.1275 - accuracy: 0.9636\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0398 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.1053 - accuracy: 0.9636\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 499us/step - loss: 0.0984 - accuracy: 0.9455\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0207 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0395 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0533 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.1195 - accuracy: 0.9455\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0493 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0534 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 798us/step - loss: 0.0475 - accuracy: 0.9636\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.1157 - accuracy: 0.9636\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.0338 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0290 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0872 - accuracy: 0.9455\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0290 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0238 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0444 - accuracy: 0.9818\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.0200 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(np.array(train_x), np.array(train_y), epochs=200, batch_size=5, verbose=1)\n",
    "model.save('chatbot_model.h5', hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model created\n"
     ]
    }
   ],
   "source": [
    "print(\"model created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('chatbot_model.h5')\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "intents = json.loads(open(r'C:\\Users\\Acer\\sample1.json').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pickle.load(open('words.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = pickle.load(open('classes.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_sentence(sentence):\n",
    "    # tokenize the pattern - split words into array\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    # stem each word - create short form for word\n",
    "    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n",
    "    return sentence_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n",
    "def bow(sentence, words, show_details=True):\n",
    "    # tokenize the pattern\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    # bag of words - matrix of N words, vocabulary matrix\n",
    "    bag = [0]*len(words) \n",
    "    for s in sentence_words:\n",
    "        for i,w in enumerate(words):\n",
    "            if w == s: \n",
    "                # assign 1 if current word is in the vocabulary position\n",
    "                bag[i] = 1\n",
    "                if show_details:\n",
    "                    print (\"found in bag: %s\" % w)\n",
    "    return(np.array(bag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(sentence, model):\n",
    "    # filter out predictions below a threshold\n",
    "    p = bow(sentence, words,show_details=False)\n",
    "    res = model.predict(np.array([p]))[0]\n",
    "    ERROR_THRESHOLD = 0.25\n",
    "    results = [[i,r] for i,r in enumerate(res) if r>ERROR_THRESHOLD]\n",
    "    # sort by strength of probability\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResponse(ints, intents_json):\n",
    "    tag = ints[0]['intent']\n",
    "    list_of_intents = intents_json['intents']\n",
    "    for i in list_of_intents:\n",
    "        if(i['tag']== tag):\n",
    "            result = random.choice(i['responses'])\n",
    "            break\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot_response(text):\n",
    "    ints = predict_class(text, model)\n",
    "    res = getResponse(ints, intents)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter\n",
    "from tkinter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send():\n",
    "    msg = EntryBox.get(\"1.0\",'end-1c').strip()\n",
    "    EntryBox.delete(\"0.0\",END)\n",
    "    if msg != '':\n",
    "        ChatLog.config(state=NORMAL)\n",
    "        ChatLog.insert(END, \"You: \" + msg + '\\n\\n')\n",
    "        ChatLog.config(foreground=\"#442265\", font=(\"Verdana\", 12 ))\n",
    "        res = chatbot_response(msg)\n",
    "        ChatLog.insert(END, \"SDF-Bot: \" + res + '\\n\\n')\n",
    "        ChatLog.config(state=DISABLED)\n",
    "        ChatLog.yview(END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = Tk()\n",
    "base.title(\"SDF Bot\")\n",
    "base.geometry(\"400x500\")\n",
    "base.resizable(width=FALSE, height=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "ChatLog = Text(base, bd=0, bg=\"white\", height=\"8\", width=\"50\", font=\"Arial\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "ChatLog.config(state=DISABLED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrollbar = Scrollbar(base, command=ChatLog.yview, cursor=\"double_arrow\")\n",
    "ChatLog['yscrollcommand'] = scrollbar.set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "SendButton = Button(base, font=(\"Verdana\",12,'bold'), text=\"Send\", width=\"12\", height=5,\n",
    "                    bd=0, bg=\"#32de97\", activebackground=\"#ff853a\",fg='#ffffff',\n",
    "                    command= send )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "EntryBox = Text(base, bd=0, bg=\"white\",width=\"29\", height=\"5\", font=\"Arial\")\n",
    "#EntryBox.bind(\"<Return>\", send)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrollbar.place(x=376,y=6, height=386)\n",
    "ChatLog.place(x=6,y=6, height=386, width=370)\n",
    "EntryBox.place(x=128, y=401, height=90, width=265)\n",
    "SendButton.place(x=6, y=401, height=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_7636/683391358.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Acer\\AppData\\Local\\Temp/ipykernel_7636/683391358.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    python train_chatbot.py\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "python train_chatbot.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
